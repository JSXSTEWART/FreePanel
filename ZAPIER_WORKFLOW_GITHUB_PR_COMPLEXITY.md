# Zapier Workflow: GitHub PR Complexity Scorer

## Overview

This workflow automatically analyzes pull requests in GitHub and assigns complexity scores based on code metrics, assigning labels and posting comments to help teams prioritize reviews and identify risky changes before they're merged.

**What It Does:**
1. Triggers when a PR is opened or updated
2. Analyzes PR metrics (files changed, lines added/deleted, commit count)
3. Queries OpenAI to generate complexity analysis
4. Assigns labels (`complexity:low`, `complexity:medium`, `complexity:high`)
5. Posts an automated review comment with recommendations

**Use Cases:**
- Prioritize high-risk PRs for senior developer review
- Identify over-engineered changes needing simplification
- Track code quality trends over time
- Alert maintainers to potentially breaking changes

---

## Prerequisites

### Required Integrations
- âœ… GitHub account with repo access
- âœ… Zapier account (free tier sufficient)
- âœ… OpenAI API key (for GPT-4 analysis)

### Recommended Tools for Local Testing
- `curl` or Postman (test webhook payloads)
- `jq` (parse GitHub API responses)
- GitHub CLI (`gh`) for testing

### Cost Estimate
- **Zapier**: $0â€“19.99/month (depending on tasks)
- **OpenAI**: ~$0.02 per PR analysis (GPT-4 token usage)
- **GitHub**: Free (public repos) or included in team plan

---

## Step 1: Set Up GitHub Webhook Trigger

### In GitHub Repository Settings

1. Navigate to **Settings** â†’ **Webhooks**
2. Click **Add webhook**
3. Configure:
   - **Payload URL**: (will be generated by Zapier in Step 2)
   - **Content type**: `application/json`
   - **Events**: Select "Pull requests"
   - **Which events?** Check:
     - âœ… Pull request opened
     - âœ… Pull request synchronize (commits added)
     - âœ… Pull request edited

### Expected Webhook Payload

```json
{
  "action": "opened",
  "pull_request": {
    "id": 1234567,
    "number": 42,
    "title": "feat: Add user authentication",
    "body": "This PR adds OAuth2 support...",
    "user": {
      "login": "developer-name"
    },
    "created_at": "2025-12-20T10:00:00Z",
    "updated_at": "2025-12-20T10:30:00Z",
    "additions": 245,
    "deletions": 87,
    "changed_files": 8,
    "commits": 5,
    "draft": false,
    "head": {
      "sha": "abc123def456",
      "ref": "feature/auth"
    },
    "base": {
      "sha": "main",
      "ref": "main"
    }
  },
  "repository": {
    "name": "FreePanel",
    "full_name": "JSXSTEWART/FreePanel",
    "owner": {
      "login": "JSXSTEWART"
    }
  }
}
```

---

## Step 2: Create Zapier Zap

### 2A: Set Up Trigger in Zapier

1. Log into **Zapier Dashboard**
2. Click **Create** â†’ **Zap**
3. Choose trigger: **GitHub** â†’ **New Pull Request**
   - **Connection**: Link your GitHub account
   - **Repository**: Select `JSXSTEWART/FreePanel`
   - **Trigger Events**: "Pull request opened or updated"

4. Click **Test trigger**
   - Zapier generates a webhook URL
   - Add this URL to GitHub settings (Step 1)
   - Create a test PR in GitHub
   - Confirm Zapier receives the payload

### 2B: Add Formatter Step (Extract Metrics)

Sometimes the webhook data needs transformation. Use Zapier's **Formatter** to extract and calculate metrics.

**Step**: Add â†’ **Formatter by Zapier** â†’ **Text** â†’ **Replace**

Create variables for analysis:

```javascript
// Complexity Score Input Variables
files_changed: pull_request.changed_files
lines_added: pull_request.additions
lines_deleted: pull_request.deletions
total_lines_changed: pull_request.additions + pull_request.deletions
commits: pull_request.commits
title: pull_request.title
description: pull_request.body
author: pull_request.user.login
repo: repository.full_name
pr_number: pull_request.number
pr_url: pull_request.html_url
```

---

## Step 3: Query OpenAI for Complexity Analysis

### 3A: Add OpenAI Action Step

**Step**: Add â†’ **OpenAI** â†’ **Send API request**

**Configuration:**

| Field | Value |
|-------|-------|
| **Connection** | Your OpenAI API key |
| **URL** | `https://api.openai.com/v1/chat/completions` |
| **Method** | POST |
| **Headers** | `Content-Type: application/json` |

### 3B: Construct Analysis Prompt

**Request Body** (JSON):

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "system",
      "content": "You are a senior code reviewer analyzing pull request complexity. Respond in valid JSON format only, with no markdown or additional text."
    },
    {
      "role": "user",
      "content": "Analyze this pull request for complexity and risk:\n\nTitle: {{pull_request.title}}\nDescription: {{pull_request.body}}\n\nMetrics:\n- Files changed: {{files_changed}}\n- Lines added: {{lines_added}}\n- Lines deleted: {{lines_deleted}}\n- Total changes: {{total_lines_changed}}\n- Commits: {{commits}}\n\nProvide a JSON response with:\n{\n  \"complexity_score\": 1-10,\n  \"complexity_level\": \"low|medium|high\",\n  \"risk_factors\": [\"factor1\", \"factor2\"],\n  \"review_priority\": \"low|normal|high\",\n  \"recommendations\": [\"recommendation1\", \"recommendation2\"],\n  \"estimated_review_time_minutes\": number\n}"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 500
}
```

### 3C: Parse OpenAI Response

The response from OpenAI looks like:

```json
{
  "choices": [
    {
      "message": {
        "content": "{\"complexity_score\": 7, \"complexity_level\": \"high\", \"risk_factors\": [\"Large refactor\", \"Database schema change\"], \"review_priority\": \"high\", \"recommendations\": [\"Request database admin review\", \"Add migration tests\"], \"estimated_review_time_minutes\": 30}"
      }
    }
  ]
}
```

**Next Step**: Add **Formatter** â†’ **JSON** â†’ **Parse**

- **Input**: `response.choices[0].message.content`
- **Output Variables**:
  ```
  complexity_score = parsed.complexity_score
  complexity_level = parsed.complexity_level
  risk_factors = parsed.risk_factors (as comma-separated string)
  review_priority = parsed.review_priority
  recommendations = parsed.recommendations
  estimated_review_time = parsed.estimated_review_time_minutes
  ```

---

## Step 4: Apply GitHub Labels Based on Complexity

### 4A: Add Conditional Logic

**Step**: Add â†’ **Paths by Zapier**

Create branches based on complexity level:

```
Path 1: IF complexity_level == "low"
Path 2: IF complexity_level == "medium"
Path 3: IF complexity_level == "high"
```

### 4B: Add GitHub Labels Action

For each path, add **GitHub** â†’ **Add label to Issue**

**Path 1 (Low Complexity):**
- **Connection**: GitHub
- **Repository**: `JSXSTEWART/FreePanel`
- **Issue Number**: `{{pull_request.number}}`
- **Labels**: `complexity:low,review:quick`
- **Color**: Green

**Path 2 (Medium Complexity):**
- **Labels**: `complexity:medium,review:standard`
- **Color**: Yellow

**Path 3 (High Complexity):**
- **Labels**: `complexity:high,review:required,needs:attention`
- **Color**: Red

---

## Step 5: Post Analysis Comment to PR

### 5A: Format Comment with Analysis

**Step**: Add â†’ **Formatter by Zapier** â†’ **Text** â†’ **Compose**

**Template**:

```markdown
## ğŸ“Š Automated Code Review Analysis

### Complexity Metrics
- **Score**: {{complexity_score}}/10
- **Level**: {{complexity_level}}
- **Priority**: {{review_priority}}
- **Estimated Review Time**: {{estimated_review_time}} minutes

### Change Summary
- Files modified: {{files_changed}}
- Lines added: {{lines_added}}
- Lines deleted: {{lines_deleted}}
- Commits: {{commits}}

### Risk Factors Identified
{{#each risk_factors as |factor|}}
- âš ï¸ {{factor}}
{{/each}}

### Recommended Actions
{{#each recommendations as |rec|}}
- âœ… {{rec}}
{{/each}}

---

### ğŸ¤– Analysis Details
- Analysis powered by GPT-4
- Generated at {{current_time}}
- Reviewer: @{{author}}

**Questions?** Check the [Code Review Guidelines](https://wiki.freepanel.com/reviews) or ask in #code-review Slack.
```

### 5B: Post Comment to GitHub

**Step**: Add â†’ **GitHub** â†’ **Create Issue Comment**

- **Connection**: GitHub
- **Repository**: `JSXSTEWART/FreePanel`
- **Issue Number**: `{{pull_request.number}}`
- **Comment**: (use the formatted comment from 5A)

---

## Step 6: Optional - Send Slack Notification

For high-priority PRs, notify the team:

**Step**: Add â†’ **Paths** â†’ Filter by `review_priority == "high"`

**Then**: Add â†’ **Slack** â†’ **Send Message**

- **Channel**: `#pr-reviews`
- **Message Template**:

```
ğŸš¨ High Priority PR Review Needed

Repository: {{repo}}
PR #{{pr_number}}: {{pull_request.title}}
Author: @{{author}}

Complexity Score: {{complexity_score}}/10
Estimated Review Time: {{estimated_review_time}} minutes

Risk Factors: {{risk_factors}}

Link: {{pull_request.html_url}}
```

---

## Step 7: Test the Complete Workflow

### Local Testing Procedure

```bash
# 1. Create a test branch
git checkout -b test/pr-complexity-analysis

# 2. Make changes (enough to trigger analysis)
echo "// New feature" >> src/new-feature.js
echo "// Another change" >> src/another-file.js

# 3. Commit and push
git add .
git commit -m "feat: Test PR complexity analysis"
git push origin test/pr-complexity-analysis

# 4. Create PR in GitHub
# Use GitHub UI to create PR from test branch to main

# 5. Watch Zapier execution
# Dashboard â†’ Zap History â†’ Check execution logs

# 6. Verify outputs
# âœ… Check GitHub: Labels added to PR
# âœ… Check GitHub: Comment posted with analysis
# âœ… Check Slack: Notification sent (if high-priority)
```

### Debugging Checklist

| Issue | Diagnosis |
|-------|-----------|
| Zap not triggering | Check GitHub webhook URL in Settings |
| OpenAI request fails | Verify API key in Zapier OpenAI connection |
| Invalid JSON response | Check OpenAI response in Zapier logs |
| Labels not applied | Confirm label names exist in repo |
| Comment not posting | Verify GitHub token has `repo:write` permission |

---

## Step 8: Customize for Your Needs

### Sensitivity Adjustment

Modify the complexity scoring in the OpenAI prompt:

```python
# Conservative (stricter)
complexity_score = (
    (files_changed * 1.5) +      # 1.5 points per file
    (total_lines_changed / 50) +  # 1 point per 50 lines
    (commits * 0.5)               # 0.5 points per commit
)

# Moderate (balanced)
complexity_score = (
    (files_changed * 1.0) +
    (total_lines_changed / 100) +
    (commits * 0.3)
)

# Lenient (permissive)
complexity_score = (
    (files_changed * 0.5) +
    (total_lines_changed / 200) +
    (commits * 0.1)
)
```

### Add Custom Rules

```javascript
// Skip analysis for specific patterns
if (pull_request.title.includes("chore:") ||
    pull_request.title.includes("docs:")) {
    skip_analysis = true;
    label = "complexity:minimal";
}

// Force high priority for specific paths
if (pull_request.changed_files.includes("app/Services/Ssl/*") ||
    pull_request.changed_files.includes("app/Services/Database/*")) {
    review_priority = "high";
    force_manual_review = true;
}
```

### Integration with Other Tools

**Add Microsoft Teams Notification**:
```
Paths â†’ filter by review_priority == "high"
â†“
Microsoft Teams â†’ Post Message to Channel
â†“
Notify #development team
```

**Add Jira Ticket Update**:
```
OpenAI Analysis Complete
â†“
Jira â†’ Create Issue or Update Issue
â†“
Set priority field based on complexity_score
```

---

## Configuration Examples

### Example 1: Conservative Setup (Enterprise)

**Scenario**: High-security team that needs thorough reviews

```yaml
OpenAI Model: gpt-4
Temperature: 0.3  # More consistent scoring
Complexity Threshold:
  Low: 0-3
  Medium: 4-7
  High: 8-10
Auto-Block: high complexity PRs require approval
Slack Alert: All PRs >= medium complexity
Code Review SLA: High = 4 hours, Medium = 1 day
```

### Example 2: Agile Setup (Startup)

**Scenario**: Fast-moving team prioritizing velocity

```yaml
OpenAI Model: gpt-3.5-turbo  # Faster, cheaper
Temperature: 0.7  # More lenient
Complexity Threshold:
  Low: 0-4
  Medium: 5-7
  High: 8-10
Auto-Block: Only critical security PRs
Slack Alert: Only high complexity
Code Review SLA: High = 2 hours, Medium = next day
```

### Example 3: ML Integration (Data Science)

**Scenario**: Team using machine learning with data pipeline changes

```yaml
OpenAI Model: gpt-4  # Better code understanding
Additional Analysis:
  - Check for test coverage changes
  - Flag dependency updates
  - Alert on breaking changes in schemas
Custom Risk Factors:
  - "Model retraining required"
  - "Database migration needed"
  - "API contract change"
```

---

## Workflow Diagram

```
GitHub PR Created/Updated
         â†“
    Zapier Trigger
         â†“
  Extract Metrics
  (files, lines, commits)
         â†“
  Send to OpenAI GPT-4
  (complexity analysis)
         â†“
    Parse Response
  (score, risks, recs)
         â†“
   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“            â†“         â†“
 LOW       MEDIUM      HIGH
(1-3)       (4-7)      (8-10)
   â†“            â†“         â†“
Add Label   Add Label  Add Label
   â†“            â†“         â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Post Comment to PR
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â†“         â†“
  Slack    Teams
Notification Notification
(if priority) (if enabled)
```

---

## Metrics & Monitoring

### What Gets Tracked

Create a spreadsheet or dashboard with:

| Metric | Formula | Purpose |
|--------|---------|---------|
| Avg Complexity Score | Sum(scores) / Count(PRs) | Track code quality trend |
| High Priority %age | Count(high) / Count(total) | Monitor risk level |
| Review Time vs Estimate | Actual / Estimated | Improve estimation |
| Risk Accuracy | Flagged Issues / Total Issues | Refine AI prompt |

### Sample Monthly Report

```
November 2025 Code Review Analysis

Total PRs Analyzed: 87
Average Complexity: 5.2/10

Breakdown:
- Low (1-3): 32 PRs (37%)
- Medium (4-7): 42 PRs (48%)
- High (8-10): 13 PRs (15%)

Most Common Risk Factors:
1. Large refactors (18 PRs)
2. Database changes (12 PRs)
3. Security-related (8 PRs)

Review Time Accuracy:
- Estimated: 456 minutes total
- Actual: 489 minutes total
- Accuracy: 93%

Recommendations:
- Improve estimation for refactors
- Create PR size limits for large changes
- Provide additional training on security reviews
```

---

## Troubleshooting

### Common Issues

**Issue**: "OpenAI request failed"
```
Solution:
1. Check API key in Zapier OpenAI connection
2. Verify API key has sufficient credits
3. Check rate limits: https://platform.openai.com/account/usage
4. Test API directly: curl https://api.openai.com/v1/models \
   -H "Authorization: Bearer sk-..."
```

**Issue**: "Labels not appearing on PR"
```
Solution:
1. Verify labels exist in GitHub repo settings
2. Check GitHub token permissions (needs repo:write)
3. Verify label names match exactly (case-sensitive)
4. Check Zapier logs for API errors
```

**Issue**: "OpenAI response is malformed"
```
Solution:
1. Validate JSON parsing in Formatter step
2. Add error handling: IF response contains error, skip label step
3. Test prompt with curl:
   curl https://api.openai.com/v1/chat/completions \
     -H "Authorization: Bearer sk-..." \
     -H "Content-Type: application/json" \
     -d '{...}'
```

---

## Advanced: GitHub API Direct Integration

### Alternative: Custom Webhook Processing

Instead of Zapier's GitHub integration, use **Webhooks by Zapier** for more control:

**Step 1: Create Custom Webhook**
```
Catch Hook Endpoint: https://hooks.zapier.com/hooks/catch/xxxxx/
```

**Step 2: Configure GitHub Webhook**
```json
{
  "url": "https://hooks.zapier.com/hooks/catch/xxxxx/",
  "content_type": "json",
  "events": ["pull_request"]
}
```

**Step 3: Process in Zapier**
```
Webhook (Catch Raw Body)
    â†“
JSON Parser (Extract fields)
    â†“
OpenAI Analysis
    â†“
GitHub API Call (Add Label)
    â†“
GitHub API Call (Post Comment)
```

This gives you more flexibility for complex scenarios.

---

## Next Steps

1. âœ… **Set up GitHub webhook** (Step 1)
2. âœ… **Create Zapier zap** (Step 2)
3. âœ… **Add OpenAI analysis** (Step 3)
4. âœ… **Apply labels** (Step 4)
5. âœ… **Post comments** (Step 5)
6. âœ… **Test end-to-end** (Step 7)
7. âœ… **Monitor and refine** (Metrics section)

---

## Resources

- [Zapier GitHub Integration Docs](https://zapier.com/apps/github/integrations)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [GitHub Webhook Events](https://docs.github.com/en/developers/webhooks-and-events/webhooks/webhook-events-and-payloads)
- [Zapier Formatter Functions](https://zapier.com/help/article/45541-formatter-functions-reference)

